{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza\n",
    "Leveraging data from the Kaggle Competition (unsubmitted): https://www.kaggle.com/c/random-acts-of-pizza/data. <br>\n",
    "Joint effort between Sarah Xie, Carolina Lee, and Ben O'Neil during Summer 2021 semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn import metrics\n",
    "import warnings as warn\n",
    "\n",
    "from scripts.length_and_date_engineering import *\n",
    "from scripts.narratives import narr_assign\n",
    "from scripts.politeness_and_image_engineering import *\n",
    "from scripts.sentiment_and_objectivity import *\n",
    "from scripts.top_words_usage import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warn.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(\"data/random-acts-of-pizza/train.json\")\n",
    "test_df = pd.read_json(\"data/random-acts-of-pizza/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df #.drop(\"requester_received_pizza\", axis=1)\n",
    "y = train_df[\"requester_received_pizza\"]\n",
    "train_df, test_df, train_label, test_label = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "Store it all in a function so it can be easily applied to both the training and test sets (as well as the test set, at the end of the modeling phase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_training_data(input_data):\n",
    "    \"\"\"Wrapper function that applies all data cleaning & feature engineering steps to the TRAIN dataset.\"\"\"\n",
    "    df = input_data.copy()\n",
    "    \n",
    "    # combine and standardize title and text in train data\n",
    "    df[\"title_and_request\"] = df[\"request_text_edit_aware\"] + \" \" + df[\"request_title\"]\n",
    "    df[\"title_and_request\"] = df[\"title_and_request\"].str.lower().str.strip()\n",
    "\n",
    "    # leverage the featuring engineering methods created on train data\n",
    "    df = create_length_of_post_and_title(df)\n",
    "    df = create_title_pentagram(df)\n",
    "    df = create_date_features(df)\n",
    "    df = create_deltas(df)\n",
    "    df[\"requester_user_flair\"] = df[\"requester_user_flair\"].replace(np.nan, \"None\")\n",
    "    df = sentiment(df)\n",
    "    df = subjectivity(df)\n",
    "    df = has_text_binary_column_creator(df, image_text, \"has_image\")\n",
    "    df = has_text_binary_column_creator(df,reciprocity_text,\"has_reciprocity\")\n",
    "    df = has_text_binary_column_creator(df,polite_text,\"has_polite\")\n",
    "    df = narr_assign(df)\n",
    "    df, top_words = key_words_usage(df)\n",
    "    \n",
    "    # subset columns\n",
    "    COLS_TO_KEEP = [\"request_number_of_comments_at_retrieval\",\n",
    "                    \"requester_account_age_in_days_at_request\",\n",
    "                    \"change_in_number_requester_comments\",\n",
    "                    \"change_in_number_requester_comments_raop\",\n",
    "                    \"change_in_number_requester_posts\",\n",
    "                    \"change_in_number_requester_posts_raop\",\n",
    "                    \"change_in_requester_vote_status\", \n",
    "                    \"change_in_requester_engagement\",\n",
    "                    \"total_request_votes_at_retrieval\",\n",
    "                    \"percent_request_upvotes_at_retrieval\",\n",
    "                    \"requester_days_since_first_post_on_raop_at_request\",\n",
    "                    \"requester_number_of_subreddits_at_request\", \n",
    "                    \"length_of_original_post\",\n",
    "                    \"length_of_title\", \"day_of_week\", \"month_of_year\", \"time_bucket\",\n",
    "                    \"sentiment\", \"subjectivity\", \"has_image\", \"has_reciprocity\",\n",
    "                    \"has_polite\", \"money_check\", \"job_check\",\n",
    "                    \"student_check\", \"family_check\", \"craving_check\", \"key_words_usage\"]\n",
    "    \n",
    "    df = df[COLS_TO_KEEP]\n",
    "    \n",
    "    # one-hot encode the categorical features\n",
    "    OHE_COLS = [\"day_of_week\", \"month_of_year\", \"time_bucket\"]\n",
    "    ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "    ohe.fit(df[OHE_COLS])\n",
    "    transformed_df = pd.DataFrame(ohe.transform(df[OHE_COLS]),\n",
    "                                  columns=ohe.get_feature_names(input_features=OHE_COLS))\n",
    "    \n",
    "    df = df.drop(OHE_COLS, axis=1).reset_index(drop=True)\n",
    "    df = pd.concat([df, transformed_df], axis=1)\n",
    "\n",
    "    df = df.replace(np.nan, 0)\n",
    "    \n",
    "    return df, top_words, ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_test_data(input_data, top_word_list, one_hot_encoder):\n",
    "    \"\"\"Wrapper function that applies all data cleaning & feature engineering steps to the TEST dataset.\"\"\"\n",
    "    df = input_data.copy()\n",
    "    \n",
    "    # combine and standardize title and text in train data\n",
    "    df[\"title_and_request\"] = df[\"request_text_edit_aware\"] + \" \" + df[\"request_title\"]\n",
    "    df[\"title_and_request\"] = df[\"title_and_request\"].str.lower().str.strip()\n",
    "\n",
    "    # leverage the featuring engineering methods created on train data\n",
    "    df = create_length_of_post_and_title(df)\n",
    "    df = create_title_pentagram(df)\n",
    "    df = create_date_features(df)\n",
    "    df = create_deltas(df)\n",
    "    df[\"requester_user_flair\"] = df[\"requester_user_flair\"].replace(np.nan, \"None\")\n",
    "    df = sentiment(df)\n",
    "    df = subjectivity(df)\n",
    "    df = has_text_binary_column_creator(df, image_text, \"has_image\")\n",
    "    df = has_text_binary_column_creator(df,reciprocity_text,\"has_reciprocity\")\n",
    "    df = has_text_binary_column_creator(df,polite_text,\"has_polite\")\n",
    "    df = narr_assign(df)\n",
    "    \n",
    "    # key words usage\n",
    "    top_features = [w[0] for w in top_word_list]\n",
    "    \n",
    "    def wordCounterUsage(text):\n",
    "        count_of_key_words = 0\n",
    "        for i in top_features:\n",
    "            in_text = 1 if i in text else 0\n",
    "            count_of_key_words += in_text\n",
    "        return count_of_key_words/len(top_features)\n",
    "\n",
    "    df['key_words_usage'] = [wordCounterUsage(text) for text in df['title_and_request']]\n",
    "    \n",
    "    # subset columns\n",
    "    COLS_TO_KEEP = [\"request_number_of_comments_at_retrieval\",\n",
    "                    \"requester_account_age_in_days_at_request\",\n",
    "                    \"change_in_number_requester_comments\",\n",
    "                    \"change_in_number_requester_comments_raop\",\n",
    "                    \"change_in_number_requester_posts\",\n",
    "                    \"change_in_number_requester_posts_raop\",\n",
    "                    \"change_in_requester_vote_status\", \n",
    "                    \"change_in_requester_engagement\",\n",
    "                    \"total_request_votes_at_retrieval\",\n",
    "                    \"percent_request_upvotes_at_retrieval\",\n",
    "                    \"requester_days_since_first_post_on_raop_at_request\",\n",
    "                    \"requester_number_of_subreddits_at_request\", \n",
    "                    \"length_of_original_post\",\n",
    "                    \"length_of_title\", \"day_of_week\", \"month_of_year\", \"time_bucket\",\n",
    "                    \"sentiment\", \"subjectivity\", \"has_image\", \"has_reciprocity\",\n",
    "                    \"has_polite\", \"money_check\", \"job_check\",\n",
    "                    \"student_check\", \"family_check\", \"craving_check\", \"key_words_usage\"]\n",
    "    \n",
    "    df = df[COLS_TO_KEEP]\n",
    "    \n",
    "    # one-hot encode the categorical features\n",
    "    OHE_COLS = [\"day_of_week\", \"month_of_year\", \"time_bucket\"]\n",
    "    transformed_df = pd.DataFrame(one_hot_encoder.transform(df[OHE_COLS]),\n",
    "                                  columns=ohe.get_feature_names(input_features=OHE_COLS))\n",
    "    \n",
    "    df = df.drop(OHE_COLS, axis=1).reset_index(drop=True)\n",
    "    df = pd.concat([df, transformed_df], axis=1)\n",
    "\n",
    "    df = df.replace(np.nan, 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply data cleaning to steps above\n",
    "train_df, top_words, ohe = clean_training_data(train_df)\n",
    "train_label = train_label * 1\n",
    "test_df = clean_test_data(test_df, top_words, ohe)\n",
    "test_label = test_label * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement standard scaler\n",
    "COLS_TO_SCALE = ['request_number_of_comments_at_retrieval',\n",
    "       'requester_account_age_in_days_at_request',\n",
    "       'change_in_number_requester_comments',\n",
    "       'change_in_number_requester_comments_raop',\n",
    "       'change_in_number_requester_posts',\n",
    "       'change_in_number_requester_posts_raop',\n",
    "       'change_in_requester_vote_status', 'change_in_requester_engagement',\n",
    "       'total_request_votes_at_retrieval',\n",
    "       'percent_request_upvotes_at_retrieval',\n",
    "       'requester_days_since_first_post_on_raop_at_request',\n",
    "       'requester_number_of_subreddits_at_request', 'length_of_original_post',\n",
    "       'length_of_title', 'sentiment', 'key_words_usage']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[COLS_TO_SCALE])\n",
    "transformed_data = scaler.transform(train_df[COLS_TO_SCALE])\n",
    "scaled_train_df = train_df.copy()\n",
    "scaled_train_df[COLS_TO_SCALE] = transformed_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test_df = test_df.copy()\n",
    "transformed_data = scaler.transform(test_df[COLS_TO_SCALE])\n",
    "scaled_test_df[COLS_TO_SCALE] = transformed_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8353960396039604 \n",
      "\n",
      "ROC AUC: 0.14963982473946086 \n",
      "\n",
      "Confusion matrix:\n",
      " [[570  39]\n",
      " [ 94 105]]\n"
     ]
    }
   ],
   "source": [
    "# logistic regression for baseline\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(scaled_train_df, train_label)\n",
    "y_pred = log_model.predict(scaled_test_df)\n",
    "y_prob = log_model.predict_proba(scaled_test_df)\n",
    "y_prob = y_prob.transpose()[0]\n",
    "\n",
    "# print accuracy\n",
    "print(f\"Accuracy: {log_model.score(scaled_test_df, test_label)} \\n\")\n",
    "\n",
    "# print ROC\n",
    "print(f\"ROC AUC: {roc_auc_score(test_label, y_prob)} \\n\")\n",
    "\n",
    "# confusion matrix\n",
    "print(f\"Confusion matrix:\\n {confusion_matrix(test_label, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Modeling\n",
    "Improve upon the baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This is the place in the notebook where team members may diverge. Ben and Sarah will be trying different model types to improve upon the baseline model._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8465346534653465 \n",
      "\n",
      "ROC AUC: 0.1237674414766773 \n",
      "\n",
      "Confusion matrix:\n",
      " [[585  24]\n",
      " [100  99]]\n"
     ]
    }
   ],
   "source": [
    "# might need to scale the data, can use StandardScaler()\n",
    "rf_model = RandomForestClassifier(max_depth=100)\n",
    "rf_model.fit(train_df, train_label)\n",
    "y_pred = rf_model.predict(test_df)\n",
    "y_prob = rf_model.predict_proba(test_df)\n",
    "y_prob = y_prob.transpose()[0]\n",
    "\n",
    "# print accuracy\n",
    "print(f\"Accuracy: {rf_model.score(test_df, test_label)} \\n\")\n",
    "\n",
    "# print ROC\n",
    "print(f\"ROC AUC: {roc_auc_score(test_label, y_prob)} \\n\")\n",
    "\n",
    "# confusion matrix\n",
    "print(f\"Confusion matrix:\\n {confusion_matrix(test_label, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>change_in_number_requester_posts_raop</td>\n",
       "      <td>0.168032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>request_number_of_comments_at_retrieval</td>\n",
       "      <td>0.096129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>change_in_number_requester_comments_raop</td>\n",
       "      <td>0.070342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>change_in_requester_vote_status</td>\n",
       "      <td>0.052847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>change_in_requester_engagement</td>\n",
       "      <td>0.049944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>length_of_original_post</td>\n",
       "      <td>0.048789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>change_in_number_requester_comments</td>\n",
       "      <td>0.044091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>length_of_title</td>\n",
       "      <td>0.043733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>percent_request_upvotes_at_retrieval</td>\n",
       "      <td>0.040254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>key_words_usage</td>\n",
       "      <td>0.039781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>requester_account_age_in_days_at_request</td>\n",
       "      <td>0.038549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>requester_number_of_subreddits_at_request</td>\n",
       "      <td>0.037074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_request_votes_at_retrieval</td>\n",
       "      <td>0.036469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>change_in_number_requester_posts</td>\n",
       "      <td>0.036082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>requester_days_since_first_post_on_raop_at_req...</td>\n",
       "      <td>0.024639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  importance\n",
       "5               change_in_number_requester_posts_raop    0.168032\n",
       "0             request_number_of_comments_at_retrieval    0.096129\n",
       "3            change_in_number_requester_comments_raop    0.070342\n",
       "6                     change_in_requester_vote_status    0.052847\n",
       "7                      change_in_requester_engagement    0.049944\n",
       "12                            length_of_original_post    0.048789\n",
       "2                 change_in_number_requester_comments    0.044091\n",
       "13                                    length_of_title    0.043733\n",
       "9                percent_request_upvotes_at_retrieval    0.040254\n",
       "24                                    key_words_usage    0.039781\n",
       "1            requester_account_age_in_days_at_request    0.038549\n",
       "11          requester_number_of_subreddits_at_request    0.037074\n",
       "8                    total_request_votes_at_retrieval    0.036469\n",
       "4                    change_in_number_requester_posts    0.036082\n",
       "10  requester_days_since_first_post_on_raop_at_req...    0.024639"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect feature importance\n",
    "feature_importance = pd.DataFrame({\"features\": train_df.columns,\n",
    "                                   \"importance\": rf_model.feature_importances_})\n",
    "feature_importance.sort_values(\"importance\", ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.1529569027403025 \n",
      "\n",
      "Confusion matrix:\n",
      " [[575  34]\n",
      " [ 97 102]]\n"
     ]
    }
   ],
   "source": [
    "# try random forest again with subset of features\n",
    "SUBSET_COLS = feature_importance.sort_values(\"importance\", ascending=False).head(10)[\"features\"].tolist()\n",
    "\n",
    "rf_model = RandomForestClassifier(max_depth=100)\n",
    "rf_model.fit(train_df[SUBSET_COLS], train_label)\n",
    "y_pred = rf_model.predict(test_df[SUBSET_COLS])\n",
    "y_prob = rf_model.predict_proba(test_df[SUBSET_COLS])\n",
    "y_prob = y_prob.transpose()[0]\n",
    "\n",
    "# print ROC\n",
    "print(f\"ROC AUC: {roc_auc_score(test_label, y_prob)} \\n\")\n",
    "# confusion matrix\n",
    "print(f\"Confusion matrix:\\n {confusion_matrix(test_label, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.17393205766104744 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_model = GBC(learning_rate=1, max_depth=5)\n",
    "gb_model.fit(train_df, train_label)\n",
    "y_prob = gb_model.predict_proba(test_df)\n",
    "y_prob = y_prob.transpose()[0]\n",
    "\n",
    "print(f\"ROC AUC: {roc_auc_score(test_label, y_prob)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC with SUBSET_COLS: 0.2119794374169699 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_model = GBC(learning_rate=1, max_depth=5)\n",
    "gb_model.fit(train_df[SUBSET_COLS], train_label)\n",
    "y_prob = gb_model.predict_proba(test_df[SUBSET_COLS])\n",
    "y_prob = y_prob.transpose()[0]\n",
    "\n",
    "print(f\"ROC AUC with SUBSET_COLS: {roc_auc_score(test_label, y_prob)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors\n",
    "Second-best result against the Logistic Regression (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.3796610309346403 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(train_df, train_label)\n",
    "y_prob = knn_model.predict_proba(test_df)\n",
    "y_prob = y_prob.transpose()[0]\n",
    "\n",
    "print(f\"ROC AUC: {roc_auc_score(test_label, y_prob)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC with SUBSET_COLS: 0.36940036801412646 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(train_df[SUBSET_COLS], train_label)\n",
    "y_prob = knn_model.predict_proba(test_df[SUBSET_COLS])\n",
    "y_prob = y_prob.transpose()[0]\n",
    "\n",
    "print(f\"ROC AUC with SUBSET_COLS: {roc_auc_score(test_label, y_prob)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n",
    "Best performance so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.502652837256892 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB(var_smoothing=0.06)\n",
    "nb_model.fit(train_df, train_label)\n",
    "y_prob = nb_model.predict_proba(test_df)\n",
    "y_prob = y_prob.transpose()[0]\n",
    "\n",
    "print(f\"ROC AUC: {roc_auc_score(test_label, y_prob)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC with SUBSET_COLS: 0.5058131379392858 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB(var_smoothing=0.06)\n",
    "nb_model.fit(train_df[SUBSET_COLS], train_label)\n",
    "y_prob = nb_model.predict_proba(test_df[SUBSET_COLS])\n",
    "y_prob = y_prob.transpose()[0]\n",
    "\n",
    "print(f\"ROC AUC with SUBSET_COLS: {roc_auc_score(test_label, y_prob)} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
